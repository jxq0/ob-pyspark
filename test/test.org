* test
#+begin_src pyspark-sql :csv_files '("Details.csv")
select
    `Category`,
    count(*),
  sum(amount)
from Details group by `Category`
#+end_src

#+RESULTS:
| Category    | count(1) | sum(amount) |
|-------------+----------+-------------|
| Electronics |      308 |      166267 |
| Clothing    |      949 |      144323 |
| Furniture   |      243 |      127181 |

#+begin_src pyspark-sql :csv_files '("Details.csv")
desc Details
#+end_src

#+RESULTS:
| col_name     | data_type | comment |
|--------------+-----------+---------|
| Order ID     | string    | None    |
| Amount       | int       | None    |
| Profit       | int       | None    |
| Quantity     | int       | None    |
| Category     | string    | None    |
| Sub-Category | string    | None    |
| PaymentMode  | string    | None    |

#+begin_src pyspark-sql
select cast(5 * round(0.56987 / 0.05) as string) as a
#+end_src

#+RESULTS:
|  a |
|----|
| 55 |

#+begin_src pyspark-sql
select format_number(100 * 0.234, 2)
#+end_src

#+RESULTS:
| format_number((100 * 0.234), 2) |
|---------------------------------|
|                           23.40 |

#+begin_src python :results silent :session pyspark :var sql="wer" :var x='("er" "ewio")
print(sql)
#+end_src
