* spark
#+begin_src pyspark-sql
select cast(5 * round(0.56987 / 0.05) as string) as a
#+end_src

#+RESULTS:
|  a |
|----|
| 55 |

#+begin_src pyspark-sql
select format_number(100 * 1.234, 2)
#+end_src

#+RESULTS:
| format_number((100 * 1.234), 2) |
|---------------------------------|
|                          123.40 |

* csv
#+begin_src pyspark-sql :csv_files '("Details.csv")
select
  `Category`,
  count(*),
  sum(amount),
  unix_timestamp() as t
from Details group by `Category`
#+end_src

#+RESULTS:
| Category    | count(1) | sum(amount) |          t |
|-------------+----------+-------------+------------|
| Electronics |      308 |      166267 | 1705454959 |
| Clothing    |      949 |      144323 | 1705454959 |
| Furniture   |      243 |      127181 | 1705454959 |

#+begin_src pyspark-sql :csv_files '("Details.csv")
desc Details
#+end_src

#+RESULTS:
| col_name     | data_type | comment |
|--------------+-----------+---------|
| Order ID     | string    | None    |
| Amount       | int       | None    |
| Profit       | int       | None    |
| Quantity     | int       | None    |
| Category     | string    | None    |
| Sub-Category | string    | None    |
| PaymentMode  | string    | None    |

* json
#+begin_src pyspark-sql :csv_files '("countries_table.json")
desc countries_table
#+end_src

#+RESULTS:
| col_name        | data_type | comment |
|-----------------+-----------+---------|
| area            | double    | None    |
| cca2            | string    | None    |
| cca3            | string    | None    |
| country         | string    | None    |
| density         | double    | None    |
| densityMi       | double    | None    |
| growthRate      | double    | None    |
| landAreaKm      | double    | None    |
| netChange       | double    | None    |
| place           | bigint    | None    |
| pop1980         | double    | None    |
| pop2000         | double    | None    |
| pop2010         | double    | None    |
| pop2022         | double    | None    |
| pop2023         | double    | None    |
| pop2030         | double    | None    |
| pop2050         | double    | None    |
| rank            | bigint    | None    |
| worldPercentage | double    | None    |

#+begin_src pyspark-sql :csv_files '("countries_table.json")
select area,country,pop2023,rank from countries_table limit 10
#+end_src

#+RESULTS:
|       area | country       |      pop2023 | rank |
|------------+---------------+--------------+------|
|  3287590.0 | India         | 1428627663.0 |    1 |
|  9706961.0 | China         | 1425671352.0 |    2 |
|  9372610.0 | United States |  339996563.0 |    3 |
|  1904569.0 | Indonesia     |  277534122.0 |    4 |
|   881912.0 | Pakistan      |  240485658.0 |    5 |
|   923768.0 | Nigeria       |  223804632.0 |    6 |
|  8515767.0 | Brazil        |  216422446.0 |    7 |
|   147570.0 | Bangladesh    |  172954319.0 |    8 |
| 17098242.0 | Russia        |  144444359.0 |    9 |
|  1964375.0 | Mexico        |  128455567.0 |   10 |
